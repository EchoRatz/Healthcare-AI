#!/usr/bin/env python3
"""
üìÅ Data Manager - ‡∏ï‡∏±‡∏ß‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI System
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ

Author: Refactored Version
Date: 2025-07-31
"""
import os
import json
import csv
from typing import List, Dict, Optional, Union
from pathlib import Path
from dataclasses import dataclass


@dataclass
class ImportResult:
    """‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    success: bool
    items_imported: int
    errors: List[str]
    file_path: str
    
    def __str__(self):
        status = "‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à" if self.success else "‚ùå ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß"
        return f"{status} - {self.file_path}: {self.items_imported} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"


class TextProcessor:
    """‡∏ï‡∏±‡∏ß‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
    
    @staticmethod
    def clean_text(text: str) -> str:
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        if not text:
            return ""
        
        # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏Å‡∏¥‡∏ô
        text = ' '.join(text.split())
        
        # ‡∏•‡∏ö‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        unwanted_chars = ['\r', '\t', '\x00', '\ufffd']
        for char in unwanted_chars:
            text = text.replace(char, '')
        
        return text.strip()
    
    @staticmethod
    def split_into_chunks(text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:
        """‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏¥‡πâ‡∏ô‡πÄ‡∏•‡πá‡∏Å‡πÜ"""
        if len(text) <= chunk_size:
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = min(start + chunk_size, len(text))
            
            # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏ï‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡∏ó‡πâ‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ)
            if end < len(text):
                # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏î‡∏µ
                for i in range(end, max(start + chunk_size - 100, start), -1):
                    if text[i] in '.!?„ÄÇ':
                        end = i + 1
                        break
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            start = max(start + chunk_size - overlap, end)
        
        return chunks
    
    @staticmethod
    def extract_metadata_from_filename(file_path: str) -> Dict[str, str]:
        """‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metadata ‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå"""
        path = Path(file_path)
        filename = path.stem.lower()
        
        # ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
        categories = {
            'python': 'programming',
            'javascript': 'programming',
            'js': 'programming',
            'web': 'web_development',
            'html': 'web_development',
            'css': 'web_development',
            'react': 'web_development',
            'machine_learning': 'ai',
            'ml': 'ai',
            'ai': 'ai',
            'deep_learning': 'ai',
            'data_science': 'data',
            'database': 'database',
            'sql': 'database',
            'vector': 'database'
        }
        
        category = 'general'
        for keyword, cat in categories.items():
            if keyword in filename:
                category = cat
                break
        
        return {
            'filename': path.name,
            'category': category,
            'file_size': path.stat().st_size if path.exists() else 0,
            'file_extension': path.suffix
        }


class DataImporter:
    """‡∏ï‡∏±‡∏ß‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
    
    SUPPORTED_EXTENSIONS = {
        '.txt': 'text',
        '.md': 'markdown',
        '.json': 'json',
        '.csv': 'csv'
    }
    
    ENCODINGS = ['utf-8', 'cp874', 'latin-1', 'utf-16']
    
    def __init__(self):
        self.processor = TextProcessor()
    
    def import_file(self, file_path: str, chunk_size: int = 500) -> ImportResult:
        """‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß"""
        path = Path(file_path)
        
        if not path.exists():
            return ImportResult(
                success=False,
                items_imported=0,
                errors=[f"‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏û‡∏ö: {file_path}"],
                file_path=file_path
            )
        
        extension = path.suffix.lower()
        if extension not in self.SUPPORTED_EXTENSIONS:
            return ImportResult(
                success=False,
                items_imported=0,
                errors=[f"‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {extension}"],
                file_path=file_path
            )
        
        try:
            file_type = self.SUPPORTED_EXTENSIONS[extension]
            
            if file_type == 'text' or file_type == 'markdown':
                return self._import_text_file(file_path, chunk_size)
            elif file_type == 'json':
                return self._import_json_file(file_path)
            elif file_type == 'csv':
                return self._import_csv_file(file_path)
            
        except Exception as e:
            return ImportResult(
                success=False,
                items_imported=0,
                errors=[f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"],
                file_path=file_path
            )
    
    def _import_text_file(self, file_path: str, chunk_size: int) -> ImportResult:
        """‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        content = self._read_file_with_encoding(file_path)
        if content is None:
            return ImportResult(
                success=False,
                items_imported=0,
                errors=["‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ"],
                file_path=file_path
            )
        
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏¥‡πâ‡∏ô
        cleaned_content = self.processor.clean_text(content)
        chunks = self.processor.split_into_chunks(cleaned_content, chunk_size)
        
        # ‡∏™‡∏Å‡∏±‡∏î metadata
        base_metadata = self.processor.extract_metadata_from_filename(file_path)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤
        import_data = []
        for i, chunk in enumerate(chunks):
            if chunk.strip():  # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ä‡∏¥‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏á
                metadata = {
                    **base_metadata,
                    'chunk_index': i,
                    'total_chunks': len(chunks),
                    'chunk_preview': chunk[:50] + "..." if len(chunk) > 50 else chunk
                }
                import_data.append({
                    'text': chunk,
                    'metadata': metadata
                })
        
        return ImportResult(
            success=True,
            items_imported=len(import_data),
            errors=[],
            file_path=file_path
        )
    
    def _import_json_file(self, file_path: str) -> ImportResult:
        """‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå JSON"""
        content = self._read_file_with_encoding(file_path)
        if content is None:
            return ImportResult(
                success=False,
                items_imported=0,
                errors=["‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ"],
                file_path=file_path
            )
        
        try:
            data = json.loads(content)
            import_data = []
            
            if isinstance(data, list):
                for item in data:
                    if isinstance(item, dict) and 'text' in item:
                        import_data.append(item)
                    elif isinstance(item, str):
                        import_data.append({'text': item})
            elif isinstance(data, dict):
                if 'text' in data:
                    import_data.append(data)
                else:
                    # ‡πÅ‡∏õ‡∏•‡∏á dict ‡πÄ‡∏õ‡πá‡∏ô text
                    text = json.dumps(data, ensure_ascii=False, indent=2)
                    import_data.append({'text': text})
            
            return ImportResult(
                success=True,
                items_imported=len(import_data),
                errors=[],
                file_path=file_path
            )
            
        except json.JSONDecodeError as e:
            return ImportResult(
                success=False,
                items_imported=0,
                errors=[f"‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ú‡∏¥‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: {str(e)}"],
                file_path=file_path
            )
    
    def _import_csv_file(self, file_path: str) -> ImportResult:
        """‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå CSV"""
        try:
            import_data = []
            
            with open(file_path, 'r', encoding='utf-8', newline='') as file:
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö delimiter ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
                sample = file.read(1024)
                file.seek(0)
                
                delimiter = ','
                if ';' in sample and sample.count(';') > sample.count(','):
                    delimiter = ';'
                
                reader = csv.DictReader(file, delimiter=delimiter)
                
                for row in reader:
                    # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å
                    text_columns = ['text', 'content', 'description', 'body', 'message']
                    text = ""
                    
                    for col in text_columns:
                        if col in row and row[col]:
                            text = row[col]
                            break
                    
                    if not text:
                        # ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
                        for value in row.values():
                            if value and len(value) > 10:  # ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏û‡∏≠
                                text = value
                                break
                    
                    if text:
                        metadata = {k: v for k, v in row.items() if k != 'text'}
                        import_data.append({
                            'text': self.processor.clean_text(text),
                            'metadata': metadata
                        })
            
            return ImportResult(
                success=True,
                items_imported=len(import_data),
                errors=[],
                file_path=file_path
            )
            
        except Exception as e:
            return ImportResult(
                success=False,
                items_imported=0,
                errors=[f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô CSV: {str(e)}"],
                file_path=file_path
            )
    
    def _read_file_with_encoding(self, file_path: str) -> Optional[str]:
        """‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏î‡∏¢‡∏•‡∏≠‡∏á encoding ‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
        for encoding in self.ENCODINGS:
            try:
                with open(file_path, 'r', encoding=encoding) as file:
                    return file.read()
            except (UnicodeDecodeError, UnicodeError):
                continue
        return None
    
    def import_directory(self, directory_path: str, recursive: bool = True) -> List[ImportResult]:
        """‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå"""
        path = Path(directory_path)
        
        if not path.exists() or not path.is_dir():
            return [ImportResult(
                success=False,
                items_imported=0,
                errors=[f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {directory_path}"],
                file_path=directory_path
            )]
        
        results = []
        
        # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        pattern = "**/*" if recursive else "*"
        for file_path in path.glob(pattern):
            if file_path.is_file() and file_path.suffix.lower() in self.SUPPORTED_EXTENSIONS:
                result = self.import_file(str(file_path))
                results.append(result)
        
        return results
    
    def get_supported_formats(self) -> Dict[str, str]:
        """‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö"""
        return {
            '.txt': '‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤',
            '.md': '‡πÑ‡∏ü‡∏•‡πå Markdown',
            '.json': '‡πÑ‡∏ü‡∏•‡πå JSON',
            '.csv': '‡πÑ‡∏ü‡∏•‡πå CSV'
        }


def main():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    print("üìÅ Data Manager - ‡∏ï‡∏±‡∏ß‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    print("="*50)
    
    importer = DataImporter()
    
    print("‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö:")
    for ext, desc in importer.get_supported_formats().items():
        print(f"  {ext} - {desc}")
    
    print("\n‡πÉ‡∏™‡πà‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå:")
    
    while True:
        try:
            path_input = input("\nüìÅ ‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á (‡∏´‡∏£‡∏∑‡∏≠ 'quit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å): ").strip()
            
            if path_input.lower() in ['quit', 'exit', 'q']:
                break
            
            if not path_input:
                continue
            
            path = Path(path_input)
            
            if path.is_file():
                print(f"\nüîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå: {path_input}")
                result = importer.import_file(path_input)
                print(result)
                
                if result.errors:
                    for error in result.errors:
                        print(f"‚ùå {error}")
            
            elif path.is_dir():
                print(f"\nüîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {path_input}")
                results = importer.import_directory(path_input)
                
                total_success = sum(1 for r in results if r.success)
                total_items = sum(r.items_imported for r in results)
                
                print(f"\nüìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤:")
                print(f"  - ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {total_success}/{len(results)}")
                print(f"  - ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_items}")
                
                for result in results:
                    print(f"  {result}")
            
            else:
                print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {path_input}")
        
        except KeyboardInterrupt:
            print("\nüëã ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
            break
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")


if __name__ == "__main__":
    main()
