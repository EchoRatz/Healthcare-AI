#!/usr/bin/env python3
"""
Setup Program for Ultra Fast Llama 3.1
======================================

This setup program ensures everything is ready for the ultra-fast 
Thai healthcare Q&A system with Llama 3.1
"""

import os
import sys
import subprocess
import requests
import json
import time
from pathlib import Path

class UltraFastSetup:
    def __init__(self):
        self.success = True
        self.issues = []
        
    def print_header(self):
        """Print setup header"""
        print("âš¡ Ultra Fast Llama 3.1 Setup")
        print("=" * 40)
        print("ðŸŽ¯ Setting up 10-minute healthcare Q&A system")
        print()
    
    def check_python_version(self):
        """Check Python version"""
        print("ðŸ Checking Python version...")
        version = sys.version_info
        
        if version.major == 3 and version.minor >= 8:
            print(f"  âœ… Python {version.major}.{version.minor}.{version.micro}")
            return True
        else:
            print(f"  âŒ Python {version.major}.{version.minor}.{version.micro} (need 3.8+)")
            self.issues.append("Python 3.8+ required")
            return False
    
    def check_packages(self):
        """Check required Python packages"""
        print("ðŸ“¦ Checking Python packages...")
        
        required_packages = {
            'requests': 'requests>=2.25.0',
            'numpy': 'numpy>=1.20.0'
        }
        
        missing = []
        
        for package, install_name in required_packages.items():
            try:
                __import__(package)
                print(f"  âœ… {package}")
            except ImportError:
                print(f"  âŒ {package} (missing)")
                missing.append(install_name)
        
        if missing:
            print(f"\nðŸ’¡ Installing missing packages...")
            try:
                cmd = [sys.executable, '-m', 'pip', 'install'] + missing
                subprocess.run(cmd, check=True, capture_output=True)
                print("  âœ… Packages installed successfully")
            except subprocess.CalledProcessError as e:
                print(f"  âŒ Failed to install packages: {e}")
                self.issues.append("Could not install required packages")
                return False
        
        return True
    
    def check_ollama_service(self):
        """Check if Ollama service is running"""
        print("ðŸ¤– Checking Ollama service...")
        
        try:
            response = requests.get('http://localhost:11434/api/version', timeout=3)
            if response.status_code == 200:
                version_info = response.json()
                print(f"  âœ… Ollama running (version: {version_info.get('version', 'unknown')})")
                return True
            else:
                print(f"  âŒ Ollama service error (status: {response.status_code})")
                self.issues.append("Ollama service not responding")
                return False
        except requests.exceptions.RequestException:
            print("  âŒ Ollama service not running")
            print("  ðŸ’¡ Start with: ollama serve")
            self.issues.append("Ollama service not running")
            return False
    
    def check_llama31_models(self):
        """Check available Llama 3.1 models"""
        print("ðŸ¦™ Checking Llama 3.1 models...")
        
        try:
            response = requests.get('http://localhost:11434/api/tags', timeout=5)
            if response.status_code == 200:
                models = response.json().get('models', [])
                llama31_models = []
                
                for model in models:
                    model_name = model.get('name', '')
                    if 'llama3.1' in model_name.lower():
                        size = model.get('size', 0)
                        size_gb = size / (1024**3) if size > 0 else 0
                        llama31_models.append((model_name, size_gb))
                
                if llama31_models:
                    print(f"  âœ… Found {len(llama31_models)} Llama 3.1 model(s):")
                    for name, size in llama31_models:
                        if '70b' in name.lower():
                            quality = "ðŸ† Excellent quality, slower"
                        elif '8b' in name.lower():
                            quality = "âš¡ Good quality, faster"
                        else:
                            quality = "ðŸ“Š Standard quality"
                        
                        print(f"    â€¢ {name} ({size:.1f}GB) - {quality}")
                    
                    # Recommend best model
                    best_model = max(llama31_models, key=lambda x: x[1])  # Largest model
                    print(f"  ðŸ’¡ Recommended: {best_model[0]}")
                    return True, best_model[0]
                else:
                    print("  âŒ No Llama 3.1 models found")
                    print("  ðŸ’¡ Install with: ollama pull llama3.1:8b")
                    self.issues.append("No Llama 3.1 models available")
                    return False, None
            else:
                print("  âŒ Could not check models")
                self.issues.append("Could not check available models")
                return False, None
                
        except requests.exceptions.RequestException:
            print("  âŒ Could not connect to Ollama")
            self.issues.append("Could not connect to Ollama service")
            return False, None
    
    def check_data_files(self):
        """Check required data files"""
        print("ðŸ“ Checking data files...")
        
        required_files = [
            'Healthcare-AI-Refactored/src/infrastructure/test.csv',
            'Healthcare-AI-Refactored/src/infrastructure/results_doc/direct_extraction_corrected.txt',
            'Healthcare-AI-Refactored/src/infrastructure/results_doc2/direct_extraction_corrected.txt',
            'Healthcare-AI-Refactored/src/infrastructure/results_doc3/direct_extraction_corrected.txt'
        ]
        
        all_found = True
        
        for file_path in required_files:
            if os.path.exists(file_path):
                size = os.path.getsize(file_path)
                if 'test.csv' in file_path:
                    # Count lines in test.csv
                    with open(file_path, 'r', encoding='utf-8') as f:
                        lines = sum(1 for _ in f) - 1  # Subtract header
                    print(f"  âœ… test.csv ({lines} questions)")
                else:
                    print(f"  âœ… {os.path.basename(file_path)} ({size//1024}KB)")
            else:
                print(f"  âŒ {file_path} (missing)")
                self.issues.append(f"Missing data file: {file_path}")
                all_found = False
        
        return all_found
    
    def check_main_script(self):
        """Check if main script exists"""
        print("ðŸš€ Checking main script...")
        
        if os.path.exists('ultra_fast_llama31.py'):
            size = os.path.getsize('ultra_fast_llama31.py')
            print(f"  âœ… ultra_fast_llama31.py ({size//1024}KB)")
            return True
        else:
            print("  âŒ ultra_fast_llama31.py (missing)")
            self.issues.append("Main script missing")
            return False
    
    def test_system(self, recommended_model):
        """Test the system with a quick question"""
        if not recommended_model:
            return False
            
        print("ðŸ§ª Testing system...")
        
        try:
            # Quick test prompt
            test_prompt = """à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¹€à¸Šà¸µà¹ˆà¸¢à¸§à¸Šà¸²à¸à¸”à¹‰à¸²à¸™à¸ªà¸¸à¸‚à¸ à¸²à¸žà¹„à¸—à¸¢

à¸„à¸³à¸–à¸²à¸¡: à¸£à¸°à¸šà¸šà¸›à¸£à¸°à¸à¸±à¸™à¸ªà¸¸à¸‚à¸ à¸²à¸žà¹à¸«à¹ˆà¸‡à¸Šà¸²à¸•à¸´à¸„à¸·à¸­à¸­à¸°à¹„à¸£?

à¸•à¸­à¸šà¸ªà¸±à¹‰à¸™à¹†:"""

            response = requests.post(
                'http://localhost:11434/api/generate',
                json={
                    'model': recommended_model,
                    'prompt': test_prompt,
                    'stream': False,
                    'options': {
                        'temperature': 0.1,
                        'num_predict': 50
                    }
                },
                timeout=15
            )
            
            if response.status_code == 200:
                result = response.json()
                answer = result.get('response', '').strip()
                if answer and len(answer) > 10:
                    print(f"  âœ… System test passed")
                    print(f"    Test response: {answer[:60]}...")
                    return True
                else:
                    print("  âŒ System test failed (empty response)")
                    return False
            else:
                print(f"  âŒ System test failed (HTTP {response.status_code})")
                return False
                
        except requests.exceptions.RequestException as e:
            print(f"  âŒ System test failed: {str(e)[:50]}...")
            return False
    
    def run_setup(self):
        """Run complete setup check"""
        self.print_header()
        
        # Run all checks
        checks = [
            ("Python Version", self.check_python_version),
            ("Python Packages", self.check_packages),
            ("Ollama Service", self.check_ollama_service),
            ("Data Files", self.check_data_files),
            ("Main Script", self.check_main_script),
        ]
        
        results = {}
        for name, check_func in checks:
            results[name] = check_func()
            print()
        
        # Special handling for model check
        model_ok, recommended_model = self.check_llama31_models()
        results["Llama 3.1 Models"] = model_ok
        print()
        
        # Test system if everything looks good
        if all(results.values()) and recommended_model:
            results["System Test"] = self.test_system(recommended_model)
            print()
        
        # Summary
        self.print_summary(results, recommended_model)
        
        return all(results.values())
    
    def print_summary(self, results, recommended_model):
        """Print setup summary"""
        print("ðŸ“Š Setup Summary")
        print("-" * 20)
        
        passed = sum(1 for v in results.values() if v)
        total = len(results)
        
        for name, status in results.items():
            status_icon = "âœ…" if status else "âŒ"
            print(f"  {status_icon} {name}")
        
        print(f"\nðŸŽ¯ Status: {passed}/{total} checks passed")
        
        if passed == total:
            print("\nðŸŽ‰ SETUP COMPLETE!")
            print("ðŸš€ Ready to run: python ultra_fast_llama31.py")
            
            if recommended_model:
                if '70b' in recommended_model.lower():
                    print("â±ï¸  Expected time: 12-18 minutes (high quality)")
                    print("ðŸŽ¯ Expected accuracy: ~90-95%")
                else:
                    print("â±ï¸  Expected time: 8-12 minutes (good speed)")
                    print("ðŸŽ¯ Expected accuracy: ~85-90%")
                
                print(f"ðŸ¤– Using model: {recommended_model}")
        else:
            print("\nâš ï¸  SETUP INCOMPLETE")
            print("ðŸ”§ Issues to fix:")
            for issue in self.issues:
                print(f"  â€¢ {issue}")
            
            print("\nðŸ’¡ Common solutions:")
            if "Ollama service not running" in str(self.issues):
                print("  â€¢ Start Ollama: ollama serve")
            if "No Llama 3.1 models" in str(self.issues):
                print("  â€¢ Install model: ollama pull llama3.1:8b")
            if "Missing data file" in str(self.issues):
                print("  â€¢ Check Healthcare-AI-Refactored directory structure")
    
    def print_installation_guide(self):
        """Print installation guide for missing components"""
        print("\nðŸ“‹ Installation Guide")
        print("-" * 25)
        print("1. Install Ollama:")
        print("   â€¢ Visit: https://ollama.ai")
        print("   â€¢ Download and install for your OS")
        print("   â€¢ Run: ollama serve")
        print()
        print("2. Install Llama 3.1:")
        print("   â€¢ Fast version: ollama pull llama3.1:8b")
        print("   â€¢ High quality: ollama pull llama3.1:70b")
        print()
        print("3. Verify setup:")
        print("   â€¢ Run: python setup_ultra_fast.py")

def main():
    """Main setup function"""
    setup = UltraFastSetup()
    
    if len(sys.argv) > 1 and sys.argv[1] == '--install-guide':
        setup.print_installation_guide()
        return
    
    success = setup.run_setup()
    
    if not success:
        print("\nðŸ’¡ Run with --install-guide for detailed installation steps")
        sys.exit(1)
    else:
        print("\nðŸŽ¯ System ready for ultra-fast processing!")

if __name__ == "__main__":
    main()