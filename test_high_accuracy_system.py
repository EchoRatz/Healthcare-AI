#!/usr/bin/env python3
"""
Test script for High-Accuracy Healthcare Q&A System
==================================================

This script tests the high-accuracy system with sample questions to validate
its performance and identify areas for improvement.
"""

import asyncio
import csv
from high_accuracy_healthcare_qa_system import HighAccuracyHealthcareQA

async def test_system():
    """Test the high-accuracy system with sample questions"""
    
    print("ğŸ§ª TESTING HIGH-ACCURACY HEALTHCARE Q&A SYSTEM")
    print("=" * 50)
    
    # Initialize system
    qa_system = HighAccuracyHealthcareQA()
    
    # Test questions with expected answers
    test_questions = [
        {
            "id": "test_1",
            "question": "à¸œà¸¡à¸›à¸§à¸”à¸—à¹‰à¸­à¸‡à¸¡à¸²à¸ à¸­à¹‰à¸§à¸à¸”à¹‰à¸§à¸¢ à¸•à¸­à¸™à¸™à¸µà¹‰à¸•à¸µà¸ªà¸­à¸‡à¸¢à¸±à¸‡à¸¡à¸µà¹à¸œà¸™à¸à¹„à¸«à¸™à¹€à¸›à¸´à¸”à¸­à¸¢à¸¹à¹ˆà¹„à¸«à¸¡à¸„à¸£à¸±à¸š? à¸. Endocrinology à¸‚. Orthopedics à¸„. Emergency à¸‡. Internal Medicine",
            "expected": "à¸„",  # Emergency should be open 24/7
            "type": "emergency"
        },
        {
            "id": "test_2", 
            "question": "à¸ªà¸´à¸—à¸˜à¸´à¹ƒà¸™à¸‚à¹‰à¸­à¹ƒà¸”à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸£à¸§à¸¡à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸ªà¸´à¸—à¸˜à¸´à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œà¸‚à¸­à¸‡à¸œà¸¹à¹‰à¸¡à¸µà¸ªà¸´à¸—à¸˜à¸´à¸«à¸¥à¸±à¸à¸›à¸£à¸°à¸à¸±à¸™à¸ªà¸¸à¸‚à¸ à¸²à¸à¹à¸«à¹ˆà¸‡à¸Šà¸²à¸•à¸´? à¸. à¸ªà¸´à¸—à¸˜à¸´à¸«à¸¥à¸±à¸à¸›à¸£à¸°à¸à¸±à¸™à¸ªà¸¸à¸‚à¸ à¸²à¸à¹à¸«à¹ˆà¸‡à¸Šà¸²à¸•à¸´ à¸‚. à¸ªà¸´à¸—à¸˜à¸´à¸šà¸±à¸•à¸£à¸—à¸­à¸‡ à¸„. à¸ªà¸´à¸—à¸˜à¸´ 30 à¸šà¸²à¸—à¸£à¸±à¸à¸©à¸²à¸—à¸¸à¸à¹‚à¸£à¸„ à¸‡. à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¹ƒà¸”à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡",
            "expected": "à¸‡",  # All are part of the system
            "type": "exclusion"
        },
        {
            "id": "test_3",
            "question": "à¸à¸²à¸£à¸œà¹ˆà¸²à¸„à¸¥à¸­à¸”à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰à¸ªà¸´à¸—à¸˜à¸´à¸«à¸¥à¸±à¸à¸›à¸£à¸°à¸à¸±à¸™à¸ªà¸¸à¸‚à¸ à¸²à¸à¹à¸«à¹ˆà¸‡à¸Šà¸²à¸•à¸´à¹„à¸”à¹‰à¹ƒà¸™à¸à¸£à¸“à¸µà¹ƒà¸”? à¸. à¹€à¸¡à¸·à¹ˆà¸­à¸¡à¸²à¸£à¸”à¸²à¸‚à¸­à¹ƒà¸«à¹‰à¹à¸à¸—à¸¢à¹Œà¸œà¹ˆà¸²à¸„à¸¥à¸­à¸”à¹€à¸à¸£à¸²à¸°à¸à¸¥à¸±à¸§à¹€à¸ˆà¹‡à¸šà¸„à¸£à¸£à¸ à¹Œ à¸‚. à¹€à¸¡à¸·à¹ˆà¸­à¹à¸à¸—à¸¢à¹Œà¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¹à¸¥à¸°à¸¡à¸µà¸‚à¹‰à¸­à¸šà¹ˆà¸‡à¸Šà¸µà¹‰à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ à¸„. à¹€à¸¡à¸·à¹ˆà¸­à¸¡à¸²à¸£à¸”à¸²à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸à¸§à¸±à¸™à¸„à¸¥à¸­à¸”à¹€à¸­à¸‡ à¸‡. à¹€à¸¡à¸·à¹ˆà¸­à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸šà¹ˆà¸‡à¸Šà¸µà¹‰à¸‚à¸­à¸‡à¹à¸à¸—à¸¢à¹Œ",
            "expected": "à¸‚",  # Medical indication required
            "type": "procedure"
        },
        {
            "id": "test_4",
            "question": "à¸„à¸™à¹„à¸‚à¹‰à¸Šà¸²à¸¢à¸­à¸²à¸¢à¸¸ 50 à¸›à¸µ à¸¡à¸µà¸­à¸²à¸à¸²à¸£à¸›à¸§à¸”à¸«à¸¥à¸±à¸‡ à¸Šà¸²à¸›à¸¥à¸²à¸¢à¸¡à¸·à¸­ à¸›à¸§à¸”à¸¥à¸‡à¸‚à¸² à¸„à¸§à¸£à¸à¸šà¸«à¸¡à¸­à¹à¸œà¸™à¸à¹„à¸«à¸™? à¸. Neurology à¸‚. Orthopedics à¸„. Cardiology à¸‡. Nephrology",
            "expected": "à¸‚",  # Orthopedics for back pain
            "type": "department"
        },
        {
            "id": "test_5",
            "question": "à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸«à¸²à¸à¸²à¸£à¸•à¸´à¸”à¹€à¸Šà¸·à¹‰à¸­à¹€à¸­à¸Šà¹„à¸­à¸§à¸µà¸”à¹‰à¸§à¸¢à¸•à¸™à¹€à¸­à¸‡ (HIVSST) à¸ªà¸²à¸¡à¸²à¸£à¸–à¸—à¸³à¹„à¸”à¹‰à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™à¸à¸µà¹ˆà¸„à¸£à¸±à¹‰à¸‡à¸•à¹ˆà¸­à¸§à¸±à¸™? à¸. 1 à¸„à¸£à¸±à¹‰à¸‡ à¸‚. 2 à¸„à¸£à¸±à¹‰à¸‡ à¸„. 3 à¸„à¸£à¸±à¹‰à¸‡ à¸‡. à¹„à¸¡à¹ˆà¸ˆà¸³à¸à¸±à¸”",
            "expected": "à¸",  # Usually limited to 1 per day
            "type": "factual"
        }
    ]
    
    print(f"ğŸ“ Testing {len(test_questions)} sample questions...")
    
    # Load knowledge base
    qa_system.load_knowledge_base()
    
    results = []
    correct = 0
    
    for test_q in test_questions:
        print(f"\nğŸ” Testing Question {test_q['id']}: {test_q['type']}")
        print(f"Question: {test_q['question'][:100]}...")
        
        # Parse question
        question, choices = qa_system.parse_question_enhanced(test_q['question'])
        
        # Analyze question
        question_analysis = qa_system.analyze_question_advanced(question)
        print(f"  Analysis: {question_analysis.primary_type} (confidence: {question_analysis.confidence:.2f})")
        
        # Search context
        context_matches = qa_system.search_context_semantic(question_analysis)
        print(f"  Context matches: {len(context_matches)} (best score: {max([m.relevance_score for m in context_matches]) if context_matches else 0:.2f})")
        
        # Query LLM (if available)
        if qa_system.check_llama31():
            answers, confidence = qa_system.query_llama31_optimized(question, choices, context_matches, question_analysis)
            print(f"  LLM Answer: {answers} (confidence: {confidence:.2f})")
        else:
            print("  âš ï¸  LLM not available - skipping LLM query")
            answers, confidence = [], 0.0
        
        # Validate answer
        answer_analysis = qa_system.validate_answer_advanced(question, choices, answers, question_analysis)
        print(f"  Validation: {answer_analysis.reasoning}")
        
        # Check correctness
        final_answer = ",".join(answer_analysis.selected_answers) if answer_analysis.selected_answers else "à¸‡"
        is_correct = final_answer == test_q['expected']
        if is_correct:
            correct += 1
        
        print(f"  Final Answer: {final_answer} | Expected: {test_q['expected']} | {'âœ…' if is_correct else 'âŒ'}")
        
        results.append({
            'id': test_q['id'],
            'type': test_q['type'],
            'expected': test_q['expected'],
            'actual': final_answer,
            'correct': is_correct,
            'confidence': confidence,
            'validation_passed': answer_analysis.policy_validation,
            'context_relevance': max([m.relevance_score for m in context_matches]) if context_matches else 0.0
        })
    
    # Print summary
    accuracy = correct / len(test_questions) * 100
    print(f"\nğŸ“Š TEST RESULTS SUMMARY:")
    print(f"  Total questions: {len(test_questions)}")
    print(f"  Correct answers: {correct}")
    print(f"  Accuracy: {accuracy:.1f}%")
    
    # Breakdown by question type
    type_results = {}
    for result in results:
        qtype = result['type']
        if qtype not in type_results:
            type_results[qtype] = {'total': 0, 'correct': 0}
        type_results[qtype]['total'] += 1
        if result['correct']:
            type_results[qtype]['correct'] += 1
    
    print(f"\nğŸ“‹ Results by Question Type:")
    for qtype, stats in type_results.items():
        type_accuracy = stats['correct'] / stats['total'] * 100
        print(f"  {qtype}: {stats['correct']}/{stats['total']} ({type_accuracy:.1f}%)")
    
    # Average confidence and context relevance
    avg_confidence = sum(r['confidence'] for r in results) / len(results)
    avg_context_relevance = sum(r['context_relevance'] for r in results) / len(results)
    validation_rate = sum(1 for r in results if r['validation_passed']) / len(results) * 100
    
    print(f"\nğŸ“ˆ Performance Metrics:")
    print(f"  Average confidence: {avg_confidence:.3f}")
    print(f"  Average context relevance: {avg_context_relevance:.3f}")
    print(f"  Validation pass rate: {validation_rate:.1f}%")
    
    return results, accuracy

async def main():
    """Main test function"""
    try:
        results, accuracy = await test_system()
        
        if accuracy >= 75:
            print(f"\nğŸ‰ SUCCESS! System achieved {accuracy:.1f}% accuracy (target: 75%)")
        else:
            print(f"\nâš ï¸  System achieved {accuracy:.1f}% accuracy (target: 75%) - needs improvement")
        
        # Save test results
        with open('test_results.csv', 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=['id', 'type', 'expected', 'actual', 'correct', 'confidence', 'validation_passed', 'context_relevance'])
            writer.writeheader()
            for result in results:
                writer.writerow(result)
        
        print(f"ğŸ’¾ Test results saved to: test_results.csv")
        
    except Exception as e:
        print(f"âŒ Test failed with error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main()) 