#!/usr/bin/env python3
"""
Test Improved Healthcare Q&A System
===================================

Test script to validate the improved system and compare with original implementation
"""

import os
import sys
import csv
import time
from improved_healthcare_qa_system import ImprovedHealthcareQA

def test_single_question():
    """Test the system with a single question"""
    print("ðŸ§ª Testing single question...")
    
    qa_system = ImprovedHealthcareQA()
    
    # Test question (from the dataset)
    test_question = {
        'id': '1',
        'question': 'à¸œà¸¡à¸›à¸§à¸”à¸—à¹‰à¸­à¸‡à¸¡à¸²à¸ à¸­à¹‰à¸§à¸à¸”à¹‰à¸§à¸¢ à¸•à¸­à¸™à¸™à¸µà¹‰à¸•à¸µà¸ªà¸­à¸‡à¸¢à¸±à¸‡à¸¡à¸µà¹à¸œà¸™à¸à¹„à¸«à¸™à¹€à¸›à¸´à¸”à¸­à¸¢à¸¹à¹ˆà¹„à¸«à¸¡à¸„à¸£à¸±à¸š?  à¸. Endocrinology à¸‚. Orthopedics à¸„. Emergency à¸‡. Internal Medicine'
    }
    
    # Parse question
    question, choices = qa_system.parse_question(test_question['question'])
    print(f"Question: {question}")
    print(f"Choices: {choices}")
    
    # Analyze question
    analysis = qa_system.analyze_question(question)
    print(f"Analysis: {analysis}")
    
    # Load knowledge base
    qa_system.load_knowledge_base()
    
    # Search context
    context = qa_system.search_context(analysis)
    print(f"Context length: {len(context)} chars")
    
    # Query LLM (if available)
    if qa_system.check_llama31():
        answers, confidence = qa_system.query_llama31_enhanced(question, choices, context)
        print(f"Answers: {answers}")
        print(f"Confidence: {confidence}")
        
        # Validate
        validation = qa_system.validate_answer_enhanced(question, choices, answers, context)
        print(f"Validation: {validation}")
    else:
        print("âŒ Llama 3.1 not available for testing")

def test_question_analysis():
    """Test question analysis with various question types"""
    print("\nðŸ” Testing question analysis...")
    
    qa_system = ImprovedHealthcareQA()
    
    test_questions = [
        "à¸ªà¸´à¸—à¸˜à¸´à¹ƒà¸™à¸‚à¹‰à¸­à¹ƒà¸”à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸£à¸§à¸¡à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸ªà¸´à¸—à¸˜à¸´à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œà¸‚à¸­à¸‡à¸œà¸¹à¹‰à¸¡à¸µà¸ªà¸´à¸—à¸˜à¸´à¸«à¸¥à¸±à¸à¸›à¸£à¸°à¸à¸±à¸™à¸ªà¸¸à¸‚à¸ à¸²à¸žà¹à¸«à¹ˆà¸‡à¸Šà¸²à¸•à¸´?",
        "à¸„à¹ˆà¸²à¸šà¸£à¸´à¸à¸²à¸£à¹€à¸„à¸¥à¸·à¸­à¸šà¸Ÿà¸¥à¸¹à¸­à¸­à¹„à¸£à¸”à¹Œà¸Šà¸™à¸´à¸”à¹€à¸‚à¹‰à¸¡à¸‚à¹‰à¸™à¸ªà¸¹à¸‡à¹€à¸‰à¸žà¸²à¸°à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸±à¸•à¸£à¸²à¹€à¸«à¸¡à¸²à¸ˆà¹ˆà¸²à¸¢à¹€à¸—à¹ˆà¸²à¹ƒà¸”à¸•à¹ˆà¸­à¸„à¸£à¸±à¹‰à¸‡?",
        "à¸‚à¹‰à¸­à¹ƒà¸”à¸•à¹ˆà¸­à¹„à¸›à¸™à¸µà¹‰à¹€à¸›à¹‡à¸™à¸­à¸²à¸à¸²à¸£à¸‰à¸¸à¸à¹€à¸‰à¸´à¸™à¸§à¸´à¸à¸¤à¸•à¸—à¸µà¹ˆà¹€à¸‚à¹‰à¸²à¸‚à¹ˆà¸²à¸¢à¸ªà¸´à¸—à¸˜à¸´ UCEP?",
        "à¸à¸²à¸£à¸œà¹ˆà¸²à¸„à¸¥à¸­à¸”à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰à¸ªà¸´à¸—à¸˜à¸´à¸«à¸¥à¸±à¸à¸›à¸£à¸°à¸à¸±à¸™à¸ªà¸¸à¸‚à¸ à¸²à¸žà¹à¸«à¹ˆà¸‡à¸Šà¸²à¸•à¸´à¹„à¸”à¹‰à¹ƒà¸™à¸à¸£à¸“à¸µà¹ƒà¸”?",
        "à¸œà¸¹à¹‰à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹ƒà¸ªà¹ˆà¸Ÿà¸±à¸™à¸›à¸¥à¸­à¸¡à¸•à¹‰à¸­à¸‡à¸¡à¸µà¸­à¸²à¸¢à¸¸à¹€à¸—à¹ˆà¸²à¹ƒà¸”à¸‚à¸¶à¹‰à¸™à¹„à¸›?"
    ]
    
    for i, question in enumerate(test_questions, 1):
        analysis = qa_system.analyze_question(question)
        print(f"\nQuestion {i}: {question}")
        print(f"  Type: {analysis.question_type}")
        print(f"  Keywords: {analysis.keywords}")
        print(f"  Entities: {analysis.entities}")
        print(f"  Confidence: {analysis.confidence:.2f}")

def test_knowledge_base_indexing():
    """Test knowledge base indexing"""
    print("\nðŸ“š Testing knowledge base indexing...")
    
    qa_system = ImprovedHealthcareQA()
    qa_system.load_knowledge_base()
    
    print(f"Indexed keywords: {len(qa_system.knowledge_base)}")
    
    # Test search for specific terms
    test_keywords = ["à¸ªà¸´à¸—à¸˜à¸´", "à¸«à¸¥à¸±à¸à¸›à¸£à¸°à¸à¸±à¸™", "à¸ªà¸¸à¸‚à¸ à¸²à¸ž", "à¸à¸²à¸£à¸£à¸±à¸à¸©à¸²", "à¸¢à¸²"]
    
    for keyword in test_keywords:
        if keyword in qa_system.knowledge_base:
            sections = qa_system.knowledge_base[keyword]
            print(f"  {keyword}: {len(sections)} sections")
        else:
            print(f"  {keyword}: Not found")

def test_answer_extraction():
    """Test answer extraction patterns"""
    print("\nðŸ“ Testing answer extraction...")
    
    qa_system = ImprovedHealthcareQA()
    
    test_responses = [
        "à¸„à¸³à¸•à¸­à¸š: à¸",
        "à¸•à¸­à¸š: à¸‚,à¸„",
        "à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸„à¸·à¸­ à¸‡",
        "à¸ à¹à¸¥à¸° à¸‚ à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡",
        "à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¹ƒà¸”à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ à¸‡",
        "à¸„à¸³à¸•à¸­à¸šà¸„à¸·à¸­ à¸,à¸‚,à¸„",
        "à¸•à¸­à¸š à¸"
    ]
    
    choices = {'à¸': 'Choice A', 'à¸‚': 'Choice B', 'à¸„': 'Choice C', 'à¸‡': 'Choice D'}
    
    for response in test_responses:
        answers = qa_system._extract_answers_enhanced(response, choices)
        print(f"Response: {response}")
        print(f"  Extracted: {answers}")

def test_validation_logic():
    """Test answer validation logic"""
    print("\nâœ… Testing validation logic...")
    
    qa_system = ImprovedHealthcareQA()
    
    test_cases = [
        {
            'question': 'à¸ªà¸´à¸—à¸˜à¸´à¹ƒà¸™à¸‚à¹‰à¸­à¹ƒà¸”à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸£à¸§à¸¡à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸ªà¸´à¸—à¸˜à¸´à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œà¸‚à¸­à¸‡à¸œà¸¹à¹‰à¸¡à¸µà¸ªà¸´à¸—à¸˜à¸´à¸«à¸¥à¸±à¸à¸›à¸£à¸°à¸à¸±à¸™à¸ªà¸¸à¸‚à¸ à¸²à¸žà¹à¸«à¹ˆà¸‡à¸Šà¸²à¸•à¸´?',
            'choices': {
                'à¸': 'à¸ªà¸´à¸—à¸˜à¸´à¸«à¸¥à¸±à¸à¸›à¸£à¸°à¸à¸±à¸™à¸ªà¸¸à¸‚à¸ à¸²à¸žà¹à¸«à¹ˆà¸‡à¸Šà¸²à¸•à¸´',
                'à¸‚': 'à¸ªà¸´à¸—à¸˜à¸´à¸šà¸±à¸•à¸£à¸—à¸­à¸‡', 
                'à¸„': 'à¸ªà¸´à¸—à¸˜à¸´ 30 à¸šà¸²à¸—à¸£à¸±à¸à¸©à¸²à¸—à¸¸à¸à¹‚à¸£à¸„',
                'à¸‡': 'à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¹ƒà¸”à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡'
            },
            'answers': ['à¸‚', 'à¸‡', 'à¸'],
            'expected_issue': 'Contradiction with à¸‡'
        },
        {
            'question': 'à¸„à¹ˆà¸²à¸šà¸£à¸´à¸à¸²à¸£à¹€à¸„à¸¥à¸·à¸­à¸šà¸Ÿà¸¥à¸¹à¸­à¸­à¹„à¸£à¸”à¹Œà¸¡à¸µà¸­à¸±à¸•à¸£à¸²à¹€à¸—à¹ˆà¸²à¹ƒà¸”?',
            'choices': {
                'à¸': '50 à¸šà¸²à¸—',
                'à¸‚': '75 à¸šà¸²à¸—',
                'à¸„': '100 à¸šà¸²à¸—', 
                'à¸‡': '150 à¸šà¸²à¸—'
            },
            'answers': ['à¸', 'à¸‚', 'à¸„', 'à¸‡'],
            'expected_issue': 'All choices selected'
        },
        {
            'question': 'à¸‚à¹‰à¸­à¹ƒà¸”à¹€à¸›à¹‡à¸™à¸­à¸²à¸à¸²à¸£à¸‰à¸¸à¸à¹€à¸‰à¸´à¸™?',
            'choices': {
                'à¸': 'à¹€à¸ˆà¹‡à¸šà¸«à¸™à¹‰à¸²à¸­à¸à¹€à¸‰à¸µà¸¢à¸šà¸žà¸¥à¸±à¸™',
                'à¸‚': 'à¸›à¸§à¸”à¸«à¸±à¸§',
                'à¸„': 'à¸¡à¸µà¹„à¸‚à¹‰',
                'à¸‡': 'à¸›à¸§à¸”à¸—à¹‰à¸­à¸‡à¹€à¸£à¸·à¹‰à¸­à¸£à¸±à¸‡'
            },
            'answers': ['à¸'],
            'expected_issue': 'Valid answer'
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f"\nTest case {i}:")
        validation = qa_system.validate_answer_enhanced(
            case['question'], 
            case['choices'], 
            case['answers'], 
            "Test context"
        )
        print(f"  Answers: {case['answers']}")
        print(f"  Valid: {validation.is_valid}")
        print(f"  Reasoning: {validation.reasoning}")
        print(f"  Expected: {case['expected_issue']}")

def compare_with_original():
    """Compare results with original implementation"""
    print("\nðŸ“Š Comparing with original implementation...")
    
    # Load original results
    original_file = "ultra_fast_submission.csv"
    improved_file = "improved_healthcare_submission.csv"
    
    if not os.path.exists(original_file):
        print(f"âŒ Original file not found: {original_file}")
        return
    
    if not os.path.exists(improved_file):
        print(f"âŒ Improved file not found: {improved_file}")
        return
    
    # Load both results
    original_results = {}
    with open(original_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            original_results[row['id']] = row['answer']
    
    improved_results = {}
    with open(improved_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            improved_results[row['id']] = row['answer']
    
    # Compare
    total_questions = len(original_results)
    same_answers = 0
    different_answers = 0
    original_none_count = 0
    improved_none_count = 0
    
    for qid in original_results:
        original_answer = original_results[qid]
        improved_answer = improved_results.get(qid, "à¸‡")
        
        if original_answer == improved_answer:
            same_answers += 1
        else:
            different_answers += 1
        
        if original_answer == "à¸‡":
            original_none_count += 1
        if improved_answer == "à¸‡":
            improved_none_count += 1
    
    print(f"Total questions: {total_questions}")
    print(f"Same answers: {same_answers} ({same_answers/total_questions*100:.1f}%)")
    print(f"Different answers: {different_answers} ({different_answers/total_questions*100:.1f}%)")
    print(f"Original 'à¸‡' answers: {original_none_count} ({original_none_count/total_questions*100:.1f}%)")
    print(f"Improved 'à¸‡' answers: {improved_none_count} ({improved_none_count/total_questions*100:.1f}%)")
    
    # Show some examples of differences
    print(f"\nExamples of different answers:")
    count = 0
    for qid in original_results:
        if count >= 5:  # Show only first 5 differences
            break
        original_answer = original_results[qid]
        improved_answer = improved_results.get(qid, "à¸‡")
        if original_answer != improved_answer:
            print(f"  Q{qid}: {original_answer} â†’ {improved_answer}")
            count += 1

def main():
    """Run all tests"""
    print("ðŸ§ª IMPROVED HEALTHCARE Q&A SYSTEM - TESTING")
    print("=" * 60)
    
    # Test individual components
    test_question_analysis()
    test_knowledge_base_indexing()
    test_answer_extraction()
    test_validation_logic()
    
    # Test single question (if LLM available)
    test_single_question()
    
    # Compare with original (if files exist)
    compare_with_original()
    
    print("\nâœ… Testing complete!")

if __name__ == "__main__":
    main() 