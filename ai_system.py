#!/usr/bin/env python3
"""
ü§ñ AI Query System - ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞
‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô 3 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó

Author: Refactored Version
Date: 2025-07-31
"""
import os
import json
import hashlib
import time
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass


@dataclass
class QueryResponse:
    """‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö"""
    message: str
    source: str
    confidence: float
    timestamp: str = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = time.strftime("%Y-%m-%d %H:%M:%S")


class VectorDatabase:
    """‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢"""
    
    def __init__(self, dimension: int = 100):
        self.dimension = dimension
        self.vectors: List[List[float]] = []
        self.metadata: List[Dict] = []
        
    def add_data(self, text: str, category: str = "general") -> bool:
        """‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        try:
            vector = self._text_to_vector(text)
            metadata = {
                "text": text,
                "category": category,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
            self.vectors.append(vector)
            self.metadata.append(metadata)
            return True
        except Exception as e:
            print(f"‚ùå Error adding data: {e}")
            return False
    
    def search_similar(self, query_text: str, threshold: float = 0.7, top_k: int = 3) -> List[Dict]:
        """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô"""
        if not self.vectors:
            return []
        
        query_vector = self._text_to_vector(query_text)
        results = []
        
        for i, vector in enumerate(self.vectors):
            similarity = self._calculate_similarity(query_vector, vector)
            
            if similarity >= threshold:
                results.append({
                    "similarity": similarity,
                    "metadata": self.metadata[i],
                    "index": i
                })
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô
        results.sort(key=lambda x: x["similarity"], reverse=True)
        return results[:top_k]
    
    def _text_to_vector(self, text: str) -> List[float]:
        """‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå"""
        text = text.lower().strip()
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏à‡∏≤‡∏Å hash ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        vector = []
        for i in range(self.dimension):
            hash_input = f"{text}_{i}"
            hash_value = int(hashlib.md5(hash_input.encode()).hexdigest(), 16)
            normalized_value = (hash_value % 10000) / 10000.0
            vector.append(normalized_value)
        
        return vector
    
    def _calculate_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì cosine similarity"""
        if len(vec1) != len(vec2):
            return 0.0
        
        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        magnitude1 = sum(a * a for a in vec1) ** 0.5
        magnitude2 = sum(b * b for b in vec2) ** 0.5
        
        if magnitude1 == 0 or magnitude2 == 0:
            return 0.0
        
        return dot_product / (magnitude1 * magnitude2)
    
    def get_stats(self) -> Dict:
        """‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        return {
            "total_items": len(self.vectors),
            "dimension": self.dimension,
            "categories": list(set(item.get("category", "unknown") for item in self.metadata))
        }


class WebSearchAnalyzer:
    """‡∏ï‡∏±‡∏ß‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
    
    WEB_KEYWORDS = [
        # ‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        "‡∏Ç‡πà‡∏≤‡∏ß", "‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î", "‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô", "‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ", "‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ", "‡∏£‡∏≤‡∏Ñ‡∏≤", "‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®",
        "‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥", "‡∏´‡∏∏‡πâ‡∏ô", "‡∏ï‡∏•‡∏≤‡∏î", "‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå", "‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå",
        
        # ‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
        "news", "latest", "current", "today", "now", "price", "weather",
        "temperature", "stock", "market", "event", "situation", "real-time"
    ]
    
    TIME_INDICATORS = [
        "‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ", "‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ", "‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô", "‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î", "‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà",
        "today", "now", "current", "latest", "when", "real-time"
    ]
    
    @classmethod
    def needs_web_search(cls, query: str) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        query_lower = query.lower()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö
        for keyword in cls.WEB_KEYWORDS:
            if keyword in query_lower:
                return True
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡πÄ‡∏ß‡∏•‡∏≤
        for indicator in cls.TIME_INDICATORS:
            if indicator in query_lower:
                return True
        
        return False


class PersonalQuestionDetector:
    """‡∏ï‡∏±‡∏ß‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß"""
    
    PERSONAL_INDICATORS = [
        # ‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        "‡∏â‡∏±‡∏ô", "‡∏Å‡∏π", "‡∏Ñ‡∏∏‡∏ì", "‡πÄ‡∏ò‡∏≠", "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô", "‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å", "‡∏ä‡∏≠‡∏ö", "‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î",
        "‡∏≠‡∏¢‡∏≤‡∏Å", "‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£", "‡∏Ñ‡∏ß‡∏£", "‡∏ô‡πà‡∏≤‡∏à‡∏∞", "‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤", "‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢",
        
        # ‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
        "i ", "you ", "my ", "your ", "opinion", "feel", "like", "love", "hate",
        "want", "should", "think", "believe", "prefer", "agree"
    ]
    
    SUBJECTIVE_WORDS = [
        "‡∏î‡∏µ", "‡πÄ‡∏•‡∏ß", "‡∏™‡∏ß‡∏¢", "‡∏ô‡πà‡∏≤‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î", "‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î", "‡πÅ‡∏¢‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î",
        "good", "bad", "beautiful", "ugly", "best", "worst", "better", "worse"
    ]
    
    @classmethod
    def is_personal_question(cls, query: str) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        query_lower = query.lower()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß
        for indicator in cls.PERSONAL_INDICATORS:
            if indicator in query_lower:
                return True
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß
        for word in cls.SUBJECTIVE_WORDS:
            if word in query_lower:
                return True
        
        return False


class AIQuerySystem:
    """‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° - ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà refactor ‡πÅ‡∏•‡πâ‡∏ß"""
    
    # ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ
    RESPONSES = {
        "no_answer": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ",
        "web_answer": "‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï",
        "vector_answer": "‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å vector database"
    }
    
    def __init__(self, vector_threshold: float = 0.7):
        self.vector_db = VectorDatabase()
        self.vector_threshold = vector_threshold
        self.web_analyzer = WebSearchAnalyzer()
        self.personal_detector = PersonalQuestionDetector()
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
        self._load_sample_data()
        
        print("ü§ñ AI Query System initialized successfully!")
        print(f"üìä Database: {self.vector_db.get_stats()['total_items']} items loaded")
    
    def _load_sample_data(self):
        """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"""
        sample_data = [
            ("Python ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏°‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô", "programming"),
            ("Machine Learning ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡πÉ‡∏ä‡πâ‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "ai"),
            ("Vector Database ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û", "database"),
            ("Deep Learning ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡∏≠‡∏á Machine Learning ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ Neural Network", "ai"),
            ("Data Science ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å", "data"),
            ("JavaScript ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏°‡∏¥‡πà‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå", "programming"),
            ("React ‡πÄ‡∏õ‡πá‡∏ô JavaScript library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á user interface", "web"),
            ("SQL ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå", "database")
        ]
        
        for text, category in sample_data:
            self.vector_db.add_data(text, category)
    
    def process_query(self, question: str) -> QueryResponse:
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö"""
        if not question or not question.strip():
            return QueryResponse(
                message=self.RESPONSES["no_answer"],
                source="validation_error",
                confidence=1.0
            )
        
        # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß
        if self.personal_detector.is_personal_question(question):
            return QueryResponse(
                message=self.RESPONSES["no_answer"],
                source="personal_question",
                confidence=0.9
            )
        
        # 2. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô Vector Database
        vector_results = self.vector_db.search_similar(question, self.vector_threshold)
        if vector_results:
            best_match = vector_results[0]
            return QueryResponse(
                message=self.RESPONSES["vector_answer"],
                source="vector_database",
                confidence=best_match["similarity"]
            )
        
        # 3. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö
        if self.web_analyzer.needs_web_search(question):
            return QueryResponse(
                message=self.RESPONSES["web_answer"],
                source="web_search",
                confidence=0.8
            )
        
        # 4. ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ
        return QueryResponse(
            message=self.RESPONSES["no_answer"],
            source="no_match",
            confidence=0.0
        )
    
    def add_knowledge(self, text: str, category: str = "user_added") -> bool:
        """‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö"""
        return self.vector_db.add_data(text, category)
    
    def get_system_info(self) -> Dict:
        """‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö"""
        db_stats = self.vector_db.get_stats()
        return {
            "system_name": "AI Query System (Refactored)",
            "version": "2.0.0",
            "database_stats": db_stats,
            "vector_threshold": self.vector_threshold,
            "response_types": list(self.RESPONSES.keys())
        }
    
    def search_knowledge(self, query: str, top_k: int = 5) -> List[Dict]:
        """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"""
        return self.vector_db.search_similar(query, threshold=0.3, top_k=top_k)


def run_interactive_demo():
    """‡πÇ‡∏´‡∏°‡∏î‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö"""
    print("\n" + "="*60)
    print("ü§ñ AI Query System - Interactive Demo")
    print("="*60)
    print("\n‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ:")
    print("  - ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö")
    print("  - 'add: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ")
    print("  - 'search: ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ")
    print("  - 'info' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏ö‡∏ö")
    print("  - 'quit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å")
    print("-"*60)
    
    ai_system = AIQuerySystem()
    
    while True:
        try:
            user_input = input("\nüí¨ ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() in ['quit', 'exit', 'q']:
                print("üëã ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
                break
            
            elif user_input.startswith('add:'):
                knowledge = user_input[4:].strip()
                if ai_system.add_knowledge(knowledge):
                    print(f"‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {knowledge}")
                else:
                    print("‚ùå ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            
            elif user_input.startswith('search:'):
                query = user_input[7:].strip()
                results = ai_system.search_knowledge(query)
                
                if results:
                    print(f"üîç ‡∏û‡∏ö {len(results)} ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:")
                    for i, result in enumerate(results, 1):
                        text = result['metadata']['text'][:50] + "..."
                        similarity = result['similarity'] * 100
                        print(f"  {i}. [{similarity:.1f}%] {text}")
                else:
                    print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô")
            
            elif user_input.lower() == 'info':
                info = ai_system.get_system_info()
                print(f"üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏ö‡∏ö:")
                print(f"  - ‡∏ä‡∏∑‡πà‡∏≠: {info['system_name']}")
                print(f"  - ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô: {info['version']}")
                print(f"  - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {info['database_stats']['total_items']}")
                print(f"  - ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà: {', '.join(info['database_stats']['categories'])}")
            
            else:
                # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥
                response = ai_system.process_query(user_input)
                
                print(f"\nüéØ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {response.message}")
                print(f"üìç ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤: {response.source}")
                print(f"üé≤ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {response.confidence:.2f}")
                print(f"‚è∞ ‡πÄ‡∏ß‡∏•‡∏≤: {response.timestamp}")
        
        except KeyboardInterrupt:
            print("\nüëã ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
            break
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")


def run_test_suite():
    """‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö"""
    print("\n" + "="*60)
    print("üß™ Running Test Suite")
    print("="*60)
    
    ai_system = AIQuerySystem()
    
    test_cases = [
        # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å Vector Database
        ("Python ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£", "vector_answer"),
        ("Machine Learning ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£", "vector_answer"),
        ("Vector Database ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£", "vector_answer"),
        
        # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö
        ("‡∏Ç‡πà‡∏≤‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ", "web_answer"),
        ("‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô", "web_answer"),
        ("‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ", "web_answer"),
        
        # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏≠‡∏ö
        ("‡∏â‡∏±‡∏ô‡∏ä‡∏≠‡∏ö‡∏™‡∏µ‡∏≠‡∏∞‡πÑ‡∏£", "no_answer"),
        ("‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤‡∏â‡∏±‡∏ô‡∏™‡∏ß‡∏¢‡πÑ‡∏´‡∏°", "no_answer"),
        ("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á", "no_answer"),
        
        # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ
        ("abcdefghijk", "no_answer"),
        ("‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏Å‡∏õ‡∏£‡∏∞‡∏´‡∏•‡∏≤‡∏î", "no_answer")
    ]
    
    correct = 0
    total = len(test_cases)
    
    for i, (question, expected) in enumerate(test_cases, 1):
        response = ai_system.process_query(question)
        expected_message = ai_system.RESPONSES[expected]
        is_correct = response.message == expected_message
        
        status = "‚úÖ" if is_correct else "‚ùå"
        print(f"{status} Test {i:2d}: {question}")
        print(f"     Expected: {expected}")
        print(f"     Got: {response.source} ({response.confidence:.2f})")
        
        if is_correct:
            correct += 1
        print()
    
    accuracy = (correct / total) * 100
    print(f"üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö: {correct}/{total} ({accuracy:.1f}%)")
    
    if accuracy == 100:
        print("üéâ ‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î!")
    else:
        print("‚ö†Ô∏è  ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö")


def main():
    """‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°"""
    print("ü§ñ AI Query System (Refactored Version)")
    print("‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô")
    print("\n‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:")
    print("1. Interactive Demo (‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö)")
    print("2. Run Tests (‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö)")
    print("3. Exit (‡∏≠‡∏≠‡∏Å)")
    
    while True:
        try:
            choice = input("\n‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (1-3): ").strip()
            
            if choice == '1':
                run_interactive_demo()
                break
            elif choice == '2':
                run_test_suite()
                break
            elif choice == '3':
                print("üëã ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
                break
            else:
                print("‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 1-3")
        
        except KeyboardInterrupt:
            print("\nüëã ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
            break


if __name__ == "__main__":
    main()
